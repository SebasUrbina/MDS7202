{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"cell_id":"97c30de09ab74ff8a8ead49b42589d52","deepnote_cell_type":"markdown","id":"XUZ1dFPHzAHl"},"source":["<h1><center>Laboratorio 9:  ¿Superhéroe o Villano?  🦴</center></h1>\n","\n","<center><strong>MDS7202: Laboratorio de Programación Científica para Ciencia de Datos</strong></center>"]},{"attachments":{},"cell_type":"markdown","metadata":{"cell_id":"44f0e095cf894684b9513510e9517584","deepnote_cell_type":"markdown","id":"UD8X1uhGzAHq"},"source":["### Cuerpo Docente:\n","\n","- Profesor: Pablo Badilla y Ignacio Meza\n","- Auxiliar: Sebastián Tinoco\n","- Ayudante: Felipe Arias y Diego Cortez"]},{"attachments":{},"cell_type":"markdown","metadata":{"cell_id":"630dba7238124007a872bee8e5ac1068","deepnote_cell_height":171.78125,"deepnote_cell_type":"markdown","id":"tXflExjqzAHr"},"source":["### Equipo: SUPER IMPORTANTE - notebooks sin nombre no serán revisados\n","\n","- Nombre de alumno 1: Carolina Salgado\n","- Nombre de alumno 2: Sebastián Urbina\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"cell_id":"b3307d6b91384799b5ffb79d87b50821","deepnote_cell_height":63,"deepnote_cell_type":"markdown","id":"AD-V0bbZzAHr"},"source":["### **Link de repositorio de GitHub:** `https://github.com/SebasUrbina/MDS7202`"]},{"attachments":{},"cell_type":"markdown","metadata":{"cell_id":"29929e237c7e4bd58e32e7014be15f5d","deepnote_cell_type":"markdown","id":"6uBLPj1PzAHs"},"source":["## Temas a tratar\n","\n","- Codificación de texto usando Bag of Words.\n","- Búsqueda del modelo óptimo de clasificación usando `GridSearch`\n","- Uso de pipelines.\n","\n","## Reglas:\n","\n","- **Grupos de 2 personas**\n","- Asistencia **obligatoria** a instrucciones del lab (viernes 16.15). Luego, pueden quedarse trabajando en las salas o irse.\n","- **No se revisarán entregas de personas ausentes**. \n","- Cualquier duda fuera del horario de clases al foro. Mensajes al equipo docente serán respondidos por este medio.\n","- Prohibidas las copias. \n","- Pueden usar cualquer material del curso que estimen conveniente.\n","\n","### Objetivos principales del laboratorio\n","\n","- Obtener caracteristicas a partir de texto usando `CountVectorizer`.\n","- Fijar un pipeline con un modelo base que luego se irá optimizando.\n","- Comprender como realizar una búsqueda de grilla sobre un conjunto de clasificadores e hiperparámetros usando `GridSearch`.\n","\n","El laboratorio deberá ser desarrollado sin el uso indiscriminado de iteradores nativos de python (aka \"for\", \"while\"). La idea es que aprendan a exprimir al máximo las funciones optimizadas que nos entrega `pandas`, las cuales vale mencionar, son bastante más eficientes que los iteradores nativos sobre DataFrames."]},{"attachments":{},"cell_type":"markdown","metadata":{"cell_id":"f5ade8a9983a447fb8a70a3f15daee03","deepnote_cell_height":52.390625,"deepnote_cell_type":"markdown","id":"MhISwri4zAHy"},"source":["#Importamos librerias utiles 😸"]},{"cell_type":"code","execution_count":1,"metadata":{"ExecuteTime":{"end_time":"2021-03-29T00:08:16.884674Z","start_time":"2021-03-29T00:08:16.349846Z"},"cell_id":"6b4998dbdd2b486f9a27fc4040ca9c26","colab":{"base_uri":"https://localhost:8080/"},"deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"executionInfo":{"elapsed":9106,"status":"ok","timestamp":1625497725070,"user":{"displayName":"IGNACIO ALEJANDRO MEZA","photoUrl":"","userId":"17011121633069169364"},"user_tz":240},"execution_millis":36497,"execution_start":1637348694866,"id":"uyc33dKdzAHy","outputId":"14d5da48-5dae-4ce4-a8ba-b826ea91a126","source_hash":"7ce9748b"},"outputs":[],"source":["# Librería Core del lab.\n","import numpy as np\n","import pandas as pd\n","from sklearn.pipeline import Pipeline\n","\n","from sklearn.model_selection import train_test_split \n","\n","# Pre-procesamiento\n","from sklearn.feature_selection import SelectPercentile, f_classif\n","from sklearn.compose import ColumnTransformer\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.feature_extraction.text import CountVectorizer\n","\n","# Clasifación\n","from sklearn.svm import SVC\n","from sklearn.naive_bayes import MultinomialNB\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.linear_model import LogisticRegression\n","\n","# Metricas de evaluación\n","from sklearn.metrics import classification_report\n","from sklearn.metrics import accuracy_score\n","from sklearn.metrics import f1_score\n","from sklearn.metrics import cohen_kappa_score\n","\n","# Librería para plotear\n","# !pip install --upgrade plotly\n","import plotly.express as px\n","from plotly.subplots import make_subplots\n","import plotly.graph_objects as go\n","\n","# Proyecciones en baja dimensionalidad: UMAP\n","# !pip install umap-learn\n","\n","# Librería para NLP\n","# !pip install nltk\n","import nltk\n","# nltk.download('punkt') # sólo 1 vez\n","from nltk.corpus import stopwords\n","from nltk import word_tokenize  \n","from nltk.stem import PorterStemmer\n","# nltk.download('stopwords') # sólo 1 vez"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["pd.options.display.max_columns = 30"]},{"attachments":{},"cell_type":"markdown","metadata":{"cell_id":"17fd1c4a7c1045a685dff360277240e7","deepnote_cell_height":82,"deepnote_cell_type":"markdown","id":"xpOTbQcxbSiy"},"source":["# 1. ¿Quien es Bat Cow?"]},{"attachments":{},"cell_type":"markdown","metadata":{"cell_id":"49b52b8931f04a2fa4287082eb3da154","deepnote_cell_height":347.8125,"deepnote_cell_type":"markdown","id":"3Q93vbNS25bM"},"source":["<p align=\"center\">\n","  <img src=\"https://i.imgur.com/D9f1RHy.jpg\" width=\"350\">\n","</p>"]},{"attachments":{},"cell_type":"markdown","metadata":{"cell_id":"98dbaf188dec4147b2b7e981fc64c61f","deepnote_cell_height":503.03125,"deepnote_cell_type":"markdown","id":"jnmZfFpxTTYX"},"source":["En vez de estar desarrollando las evaluaciones correspondientes a su curso, su profesor de catedra y su auxiliar discuten acerca la alineación (héroe o villano) del personaje de ficción Bat-Cow. \n","\n","El cuerpo docente, no logra ponerse de acuerdo si el personaje es bueno, neutral o malo: el auxiliar plantea que Bat-cow posee una siniestra mirada, intrigante pero común característica de los personajes malvados. \n","Por otra parte, extendiendo las ideas de Rousseau, el profesor plantea que tal como los humanos no nacen malos, no existe motivo por el cual una vaca con superpoderes deba serlo.\n","\n","Sin embargo, ambos concuerdan que es difícil estimar la alineación solo usando los atributos físicos, por lo que creen el análisis debe ser complementado aún más antes de comunicarle los resultados a su estudiantado. Buscando más información, ambos sujetos se percatan de la existencia de un excelente antecedente para estimar la alineación: la historia personal de cada superhéroe o villano.\n","\n","Es por esto le solicitan que construya y optimice un clasificador basado en texto el cual analice la alineación de cada personaje basado en su historia personal.\n","\n","Para este laboratorio deben trabajar con los datos `df_comics.csv` y `comics_no_label.csv` subidos a u-cursos. El primero es un conjunto de datos que les servirá para entrenar un modelo de clasificación, mientras que el segundo es un dataset con personajes de ficción no etiquetados a predecir (sí, aquí está la misteriosa Batcow).\n","\n","Para comenzar cargue los dataset señalados y visualice a través de un head los atributos que poseen cada uno de los dataset.\n"]},{"cell_type":"code","execution_count":3,"metadata":{"cell_id":"82557a3ea7744f42a77dc7f5d97629ab","colab":{"base_uri":"https://localhost:8080/"},"deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"executionInfo":{"elapsed":5,"status":"ok","timestamp":1625497735673,"user":{"displayName":"IGNACIO ALEJANDRO MEZA","photoUrl":"","userId":"17011121633069169364"},"user_tz":240},"execution_millis":27,"execution_start":1637348657022,"id":"Jqq-s010Iwl1","outputId":"bc29f770-d066-4443-8cee-00e3db46c629","source_hash":"c60dc4a7"},"outputs":[{"name":"stdout","output_type":"stream","text":["Ignorando conexión drive-colab\n"]}],"source":["# Si usted está utilizando Colaboratory le puede ser útil este código para cargar los archivos.\n","try:\n","    from google.colab import drive\n","    drive.mount(\"/content/drive\")\n","    path = 'Dirección donde tiene los archivos en el Drive'\n","except: \n","    print('Ignorando conexión drive-colab')"]},{"cell_type":"code","execution_count":4,"metadata":{"cell_id":"c4b057f299d348fa839ac3c555241045","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"executionInfo":{"elapsed":289,"status":"ok","timestamp":1625499009249,"user":{"displayName":"IGNACIO ALEJANDRO MEZA","photoUrl":"","userId":"17011121633069169364"},"user_tz":240},"execution_millis":325,"execution_start":1637348732856,"id":"bED3w3tDbSCf","source_hash":"443d6e8"},"outputs":[],"source":["df_comics = pd.read_csv('recursos/df_comics.csv')\n","df_comics_no_label = pd.read_csv('recursos/comics_no_label.csv')\n","df_comics = df_comics.dropna(subset=['history_text']) # eliminar ejemplos sin historia"]},{"cell_type":"code","execution_count":5,"metadata":{"cell_id":"4c6367f4379042cc8515e0e86849acf3","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":654,"execution_start":1637348731943,"source_hash":"b986316d","tags":[]},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>name</th>\n","      <th>real_name</th>\n","      <th>full_name</th>\n","      <th>overall_score</th>\n","      <th>history_text</th>\n","      <th>powers_text</th>\n","      <th>intelligence_score</th>\n","      <th>strength_score</th>\n","      <th>speed_score</th>\n","      <th>durability_score</th>\n","      <th>power_score</th>\n","      <th>combat_score</th>\n","      <th>superpowers</th>\n","      <th>alter_egos</th>\n","      <th>...</th>\n","      <th>has_energy_blasts</th>\n","      <th>has_enhanced_senses</th>\n","      <th>has_invulnerability</th>\n","      <th>has_stealth</th>\n","      <th>has_marksmanship</th>\n","      <th>has_flight</th>\n","      <th>has_accelerated_healing</th>\n","      <th>has_weapons_master</th>\n","      <th>has_intelligence</th>\n","      <th>has_reflexes</th>\n","      <th>has_super_speed</th>\n","      <th>has_durability</th>\n","      <th>has_stamina</th>\n","      <th>has_agility</th>\n","      <th>has_super_strength</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>3-D Man</td>\n","      <td>Delroy Garrett, Jr.</td>\n","      <td>Delroy Garrett, Jr.</td>\n","      <td>6</td>\n","      <td>Delroy Garrett, Jr. grew up to become a track ...</td>\n","      <td>NaN</td>\n","      <td>85</td>\n","      <td>30</td>\n","      <td>60</td>\n","      <td>60</td>\n","      <td>40</td>\n","      <td>70</td>\n","      <td>['Super Speed', 'Super Strength']</td>\n","      <td>[]</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>A-Bomb</td>\n","      <td>Richard Milhouse Jones</td>\n","      <td>Richard Milhouse Jones</td>\n","      <td>20</td>\n","      <td>Richard \"Rick\" Jones was orphaned at a young ...</td>\n","      <td>On rare occasions, and through unusual circu...</td>\n","      <td>80</td>\n","      <td>100</td>\n","      <td>80</td>\n","      <td>100</td>\n","      <td>100</td>\n","      <td>80</td>\n","      <td>['Accelerated Healing', 'Agility', 'Berserk Mo...</td>\n","      <td>[]</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>Aa</td>\n","      <td>Aa</td>\n","      <td>NaN</td>\n","      <td>12</td>\n","      <td>Aa is one of the more passive members of the P...</td>\n","      <td>NaN</td>\n","      <td>80</td>\n","      <td>50</td>\n","      <td>55</td>\n","      <td>45</td>\n","      <td>100</td>\n","      <td>55</td>\n","      <td>['Energy Absorption', 'Energy Armor', 'Energy ...</td>\n","      <td>[]</td>\n","      <td>...</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>Aaron Cash</td>\n","      <td>Aaron Cash</td>\n","      <td>Aaron Cash</td>\n","      <td>5</td>\n","      <td>Aaron Cash is the head of security at Arkham A...</td>\n","      <td>NaN</td>\n","      <td>80</td>\n","      <td>10</td>\n","      <td>25</td>\n","      <td>40</td>\n","      <td>30</td>\n","      <td>50</td>\n","      <td>['Weapon-based Powers', 'Weapons Master']</td>\n","      <td>[]</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>Aayla Secura</td>\n","      <td>Aayla Secura</td>\n","      <td>NaN</td>\n","      <td>8</td>\n","      <td>ayla Secura was a Rutian Twi'lek Jedi Knight (...</td>\n","      <td>NaN</td>\n","      <td>90</td>\n","      <td>40</td>\n","      <td>45</td>\n","      <td>55</td>\n","      <td>55</td>\n","      <td>85</td>\n","      <td>['Accelerated Healing', 'Agility', 'Astral Pro...</td>\n","      <td>[]</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 82 columns</p>\n","</div>"],"text/plain":["   Unnamed: 0          name               real_name               full_name   \n","0           0       3-D Man     Delroy Garrett, Jr.     Delroy Garrett, Jr.  \\\n","1           2        A-Bomb  Richard Milhouse Jones  Richard Milhouse Jones   \n","2           3            Aa                      Aa                     NaN   \n","3           4    Aaron Cash              Aaron Cash              Aaron Cash   \n","4           5  Aayla Secura            Aayla Secura                     NaN   \n","\n","  overall_score                                       history_text   \n","0             6  Delroy Garrett, Jr. grew up to become a track ...  \\\n","1            20   Richard \"Rick\" Jones was orphaned at a young ...   \n","2            12  Aa is one of the more passive members of the P...   \n","3             5  Aaron Cash is the head of security at Arkham A...   \n","4             8  ayla Secura was a Rutian Twi'lek Jedi Knight (...   \n","\n","                                         powers_text  intelligence_score   \n","0                                                NaN                  85  \\\n","1    On rare occasions, and through unusual circu...                  80   \n","2                                                NaN                  80   \n","3                                                NaN                  80   \n","4                                                NaN                  90   \n","\n","   strength_score  speed_score  durability_score  power_score  combat_score   \n","0              30           60                60           40            70  \\\n","1             100           80               100          100            80   \n","2              50           55                45          100            55   \n","3              10           25                40           30            50   \n","4              40           45                55           55            85   \n","\n","                                         superpowers alter_egos  ...   \n","0                  ['Super Speed', 'Super Strength']         []  ...  \\\n","1  ['Accelerated Healing', 'Agility', 'Berserk Mo...         []  ...   \n","2  ['Energy Absorption', 'Energy Armor', 'Energy ...         []  ...   \n","3          ['Weapon-based Powers', 'Weapons Master']         []  ...   \n","4  ['Accelerated Healing', 'Agility', 'Astral Pro...         []  ...   \n","\n","  has_energy_blasts has_enhanced_senses has_invulnerability has_stealth   \n","0               0.0                 0.0                 0.0         0.0  \\\n","1               0.0                 1.0                 1.0         1.0   \n","2               1.0                 0.0                 0.0         0.0   \n","3               0.0                 0.0                 0.0         0.0   \n","4               0.0                 0.0                 0.0         0.0   \n","\n","  has_marksmanship has_flight has_accelerated_healing has_weapons_master   \n","0              0.0        0.0                     0.0                0.0  \\\n","1              0.0        0.0                     1.0                0.0   \n","2              0.0        0.0                     0.0                0.0   \n","3              0.0        0.0                     0.0                1.0   \n","4              0.0        0.0                     1.0                0.0   \n","\n","  has_intelligence has_reflexes has_super_speed has_durability has_stamina   \n","0              0.0          0.0             1.0            0.0         0.0  \\\n","1              0.0          1.0             1.0            1.0         1.0   \n","2              0.0          0.0             0.0            0.0         0.0   \n","3              0.0          0.0             0.0            0.0         0.0   \n","4              0.0          0.0             0.0            0.0         0.0   \n","\n","  has_agility has_super_strength  \n","0         0.0                1.0  \n","1         1.0                1.0  \n","2         0.0                0.0  \n","3         0.0                0.0  \n","4         1.0                0.0  \n","\n","[5 rows x 82 columns]"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["# queda a labor de su equipo hacer el análisis exploratorio\n","df_comics.head()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Se realiza un breve análisis exploratorio."]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","Index: 1285 entries, 0 to 1366\n","Data columns (total 82 columns):\n"," #   Column                            Non-Null Count  Dtype  \n","---  ------                            --------------  -----  \n"," 0   Unnamed: 0                        1285 non-null   int64  \n"," 1   name                              1285 non-null   object \n"," 2   real_name                         1164 non-null   object \n"," 3   full_name                         894 non-null    object \n"," 4   overall_score                     1285 non-null   object \n"," 5   history_text                      1285 non-null   object \n"," 6   powers_text                       959 non-null    object \n"," 7   intelligence_score                1285 non-null   int64  \n"," 8   strength_score                    1285 non-null   int64  \n"," 9   speed_score                       1285 non-null   int64  \n"," 10  durability_score                  1285 non-null   int64  \n"," 11  power_score                       1285 non-null   int64  \n"," 12  combat_score                      1285 non-null   int64  \n"," 13  superpowers                       1285 non-null   object \n"," 14  alter_egos                        1285 non-null   object \n"," 15  aliases                           1285 non-null   object \n"," 16  place_of_birth                    734 non-null    object \n"," 17  first_appearance                  1142 non-null   object \n"," 18  creator                           1166 non-null   object \n"," 19  alignment                         1285 non-null   object \n"," 20  occupation                        938 non-null    object \n"," 21  base                              806 non-null    object \n"," 22  teams                             1285 non-null   object \n"," 23  relatives                         806 non-null    object \n"," 24  gender                            1191 non-null   object \n"," 25  type_race                         942 non-null    object \n"," 26  height                            1285 non-null   object \n"," 27  weight                            1285 non-null   object \n"," 28  eye_color                         1091 non-null   object \n"," 29  hair_color                        1101 non-null   object \n"," 30  skin_color                        154 non-null    object \n"," 31  img                               1215 non-null   object \n"," 32  has_electrokinesis                1228 non-null   float64\n"," 33  has_energy_constructs             1228 non-null   float64\n"," 34  has_mind_control_resistance       1228 non-null   float64\n"," 35  has_matter_manipulation           1228 non-null   float64\n"," 36  has_telepathy_resistance          1228 non-null   float64\n"," 37  has_mind_control                  1228 non-null   float64\n"," 38  has_enhanced_hearing              1228 non-null   float64\n"," 39  has_dimensional_travel            1228 non-null   float64\n"," 40  has_element_control               1228 non-null   float64\n"," 41  has_size_changing                 1228 non-null   float64\n"," 42  has_fire_resistance               1228 non-null   float64\n"," 43  has_fire_control                  1228 non-null   float64\n"," 44  has_dexterity                     1228 non-null   float64\n"," 45  has_reality_warping               1228 non-null   float64\n"," 46  has_illusions                     1228 non-null   float64\n"," 47  has_energy_beams                  1228 non-null   float64\n"," 48  has_peak_human_condition          1228 non-null   float64\n"," 49  has_shapeshifting                 1228 non-null   float64\n"," 50  has_heat_resistance               1228 non-null   float64\n"," 51  has_jump                          1228 non-null   float64\n"," 52  has_self-sustenance               1228 non-null   float64\n"," 53  has_energy_absorption             1228 non-null   float64\n"," 54  has_cold_resistance               1228 non-null   float64\n"," 55  has_magic                         1228 non-null   float64\n"," 56  has_telekinesis                   1228 non-null   float64\n"," 57  has_toxin_and_disease_resistance  1228 non-null   float64\n"," 58  has_telepathy                     1228 non-null   float64\n"," 59  has_regeneration                  1228 non-null   float64\n"," 60  has_immortality                   1228 non-null   float64\n"," 61  has_teleportation                 1228 non-null   float64\n"," 62  has_force_fields                  1228 non-null   float64\n"," 63  has_energy_manipulation           1228 non-null   float64\n"," 64  has_endurance                     1228 non-null   float64\n"," 65  has_longevity                     1228 non-null   float64\n"," 66  has_weapon-based_powers           1228 non-null   float64\n"," 67  has_energy_blasts                 1228 non-null   float64\n"," 68  has_enhanced_senses               1228 non-null   float64\n"," 69  has_invulnerability               1228 non-null   float64\n"," 70  has_stealth                       1228 non-null   float64\n"," 71  has_marksmanship                  1228 non-null   float64\n"," 72  has_flight                        1228 non-null   float64\n"," 73  has_accelerated_healing           1228 non-null   float64\n"," 74  has_weapons_master                1228 non-null   float64\n"," 75  has_intelligence                  1228 non-null   float64\n"," 76  has_reflexes                      1228 non-null   float64\n"," 77  has_super_speed                   1228 non-null   float64\n"," 78  has_durability                    1228 non-null   float64\n"," 79  has_stamina                       1228 non-null   float64\n"," 80  has_agility                       1228 non-null   float64\n"," 81  has_super_strength                1228 non-null   float64\n","dtypes: float64(50), int64(7), object(25)\n","memory usage: 833.2+ KB\n"]}],"source":["df_comics.info()"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 84 entries, 0 to 83\n","Data columns (total 82 columns):\n"," #   Column                            Non-Null Count  Dtype  \n","---  ------                            --------------  -----  \n"," 0   Unnamed: 0                        84 non-null     int64  \n"," 1   name                              82 non-null     object \n"," 2   real_name                         64 non-null     object \n"," 3   full_name                         11 non-null     object \n"," 4   overall_score                     84 non-null     object \n"," 5   history_text                      76 non-null     object \n"," 6   powers_text                       43 non-null     object \n"," 7   intelligence_score                84 non-null     int64  \n"," 8   strength_score                    84 non-null     int64  \n"," 9   speed_score                       84 non-null     int64  \n"," 10  durability_score                  84 non-null     int64  \n"," 11  power_score                       84 non-null     int64  \n"," 12  combat_score                      84 non-null     int64  \n"," 13  superpowers                       84 non-null     object \n"," 14  alter_egos                        84 non-null     object \n"," 15  aliases                           84 non-null     object \n"," 16  place_of_birth                    20 non-null     object \n"," 17  first_appearance                  38 non-null     object \n"," 18  creator                           74 non-null     object \n"," 19  alignment                         0 non-null      float64\n"," 20  occupation                        31 non-null     object \n"," 21  base                              25 non-null     object \n"," 22  teams                             84 non-null     object \n"," 23  relatives                         26 non-null     object \n"," 24  gender                            39 non-null     object \n"," 25  type_race                         37 non-null     object \n"," 26  height                            82 non-null     object \n"," 27  weight                            82 non-null     object \n"," 28  eye_color                         28 non-null     object \n"," 29  hair_color                        29 non-null     object \n"," 30  skin_color                        5 non-null      object \n"," 31  img                               72 non-null     object \n"," 32  has_electrokinesis                78 non-null     float64\n"," 33  has_energy_constructs             78 non-null     float64\n"," 34  has_mind_control_resistance       78 non-null     float64\n"," 35  has_matter_manipulation           78 non-null     float64\n"," 36  has_telepathy_resistance          78 non-null     float64\n"," 37  has_mind_control                  78 non-null     float64\n"," 38  has_enhanced_hearing              78 non-null     float64\n"," 39  has_dimensional_travel            78 non-null     float64\n"," 40  has_element_control               78 non-null     float64\n"," 41  has_size_changing                 78 non-null     float64\n"," 42  has_fire_resistance               78 non-null     float64\n"," 43  has_fire_control                  78 non-null     float64\n"," 44  has_dexterity                     78 non-null     float64\n"," 45  has_reality_warping               78 non-null     float64\n"," 46  has_illusions                     78 non-null     float64\n"," 47  has_energy_beams                  78 non-null     float64\n"," 48  has_peak_human_condition          78 non-null     float64\n"," 49  has_shapeshifting                 78 non-null     float64\n"," 50  has_heat_resistance               78 non-null     float64\n"," 51  has_jump                          78 non-null     float64\n"," 52  has_self-sustenance               78 non-null     float64\n"," 53  has_energy_absorption             78 non-null     float64\n"," 54  has_cold_resistance               78 non-null     float64\n"," 55  has_magic                         78 non-null     float64\n"," 56  has_telekinesis                   78 non-null     float64\n"," 57  has_toxin_and_disease_resistance  78 non-null     float64\n"," 58  has_telepathy                     78 non-null     float64\n"," 59  has_regeneration                  78 non-null     float64\n"," 60  has_immortality                   78 non-null     float64\n"," 61  has_teleportation                 78 non-null     float64\n"," 62  has_force_fields                  78 non-null     float64\n"," 63  has_energy_manipulation           78 non-null     float64\n"," 64  has_endurance                     78 non-null     float64\n"," 65  has_longevity                     78 non-null     float64\n"," 66  has_weapon-based_powers           78 non-null     float64\n"," 67  has_energy_blasts                 78 non-null     float64\n"," 68  has_enhanced_senses               78 non-null     float64\n"," 69  has_invulnerability               78 non-null     float64\n"," 70  has_stealth                       78 non-null     float64\n"," 71  has_marksmanship                  78 non-null     float64\n"," 72  has_flight                        78 non-null     float64\n"," 73  has_accelerated_healing           78 non-null     float64\n"," 74  has_weapons_master                78 non-null     float64\n"," 75  has_intelligence                  78 non-null     float64\n"," 76  has_reflexes                      78 non-null     float64\n"," 77  has_super_speed                   78 non-null     float64\n"," 78  has_durability                    78 non-null     float64\n"," 79  has_stamina                       78 non-null     float64\n"," 80  has_agility                       78 non-null     float64\n"," 81  has_super_strength                78 non-null     float64\n","dtypes: float64(51), int64(7), object(24)\n","memory usage: 53.9+ KB\n"]}],"source":["df_comics_no_label.info()"]},{"attachments":{},"cell_type":"markdown","metadata":{"cell_id":"2b5684743aec4d388edaa8f190652e9e","deepnote_cell_height":410,"deepnote_cell_type":"markdown","id":"i4tFPrFA4_O5"},"source":["## 1.1 Obtención de Features y Bag of Words\n","\n","<p align=\"center\">\n","  <img src=\"https://media0.giphy.com/media/eIUpSyzwGp0YhAMTKr/200.gif\" width=\"300\">\n","</p>"]},{"attachments":{},"cell_type":"markdown","metadata":{"cell_id":"39e5b3d761274681bdafab029d6ede31","deepnote_cell_height":561.859375,"deepnote_cell_type":"markdown","id":"f_4NF0_V5XZ-"},"source":["Primero que todo, deben obtener un vector de características del atributo `history_text`, utilizando `Bag of Words`. En este atributo se presenta una breve descripción de la historia de cada uno de los personajes de ficción presentes en el dataset. \n","\n","Pero... antes de empezar, ¿Que es `Bag of Words`?...\n","\n","`Bag of Words` es un modelo de conteo utilizado en Procesamiento de Lenguaje Natural (NLP) que tiene como objetivo generar una representación vectorial (vector de características en nuestro caso) para cada documento a través del conteo de las palabras que contienen. \n","\n","La siguiente figura muestra un ejemplo de `Bag of Words` en acción:\n","\n","<p align=\"center\">\n","  <img src=\"https://user.oc-static.com/upload/2020/10/23/16034397439042_surfin%20bird%20bow.png\" width=\"500\">\n","</p>\n","\n","Como pueden ver, el modelo de `Bag of Words` no resulta tan complicado, ¿pero cómo lo aplicamos en python?. \n","\n","Como podrán darse cuenta del ejemplo anterior, para facilitar el conteo será necesario transformar cada uno de los documentos en vectores, donde cada una de las posiciones posee un carácter. Este proceso es conocido como **tokenización** y lo podemos realizar de la siguiente forma:"]},{"cell_type":"code","execution_count":8,"metadata":{"cell_id":"4225703f5ca94caeba76b5271167c8ec","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":8,"execution_start":1637346921830,"source_hash":"57e4888a","tags":[]},"outputs":[{"data":{"text/plain":["[['The', 'teacher', 'rocks', 'like', 'a', 'good', 'rock', '&', 'roll'],\n"," ['the', 'rock', 'is', 'the', 'best', 'actor', 'in', 'the', 'world']]"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["docs = [\n","    'The teacher rocks like a good rock & roll',\n","    'the rock is the best actor in the world'\n","    ]\n","\n","\n","docs_tokenizados = [word_tokenize(doc)  for doc in docs]\n","docs_tokenizados"]},{"attachments":{},"cell_type":"markdown","metadata":{"cell_id":"38363e52900d4138aa13cfc88bb699dc","deepnote_cell_height":424.125,"deepnote_cell_type":"markdown","tags":[]},"source":["Podemos mejorar un poco más el proceso de tokenización agregando \n","\n","- Stemming:  Definimos Stemming como un algoritmo basado en reglas que transforma las palabras a una forma general. Un ejemplo de stemming, es el siguiente:\n","- Eliminación de Stopwords: Eliminación de palabras muy frecuentes que entorpecen la clasificación (por ejemplo, el, la los, la, etc...)\n","\n","<p align=\"center\">\n","  <img src=\"https://devopedia.org/images/article/218/8583.1569386710.png\" width=\"300\">\n","</p>\n"]},{"cell_type":"code","execution_count":9,"metadata":{"cell_id":"281adedd8d3e4785931934eadd57abfb","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":36,"execution_start":1637346924545,"source_hash":"d7f59237","tags":[]},"outputs":[{"data":{"text/plain":["[['the', 'teacher', 'rock', 'like', 'good', 'rock', '&', 'roll'],\n"," ['rock', 'best', 'actor', 'world'],\n"," ['new', 'york', 'beauti', 'citi']]"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["# Definimos algunas stopword que queremos que sean eliminadas\n","# import nltk\n","# nltk.download('stopwords')\n","\n","from nltk.corpus import stopwords\n","\n","stop_words = stopwords.words('english')\n","\n","# Definimos un tokenizador con Stemming\n","class StemmerTokenizer:\n","    def __init__(self):\n","        self.ps = PorterStemmer()\n","    def __call__(self, doc):\n","        doc_tok = word_tokenize(doc)\n","        doc_tok = [t for t in doc_tok if t not in stop_words]\n","        return [self.ps.stem(t) for t in doc_tok]\n","\n","# Inicializamos tokenizador\n","tokenizador = StemmerTokenizer()\n","\n","# Creamos algunos documentos\n","docs = [\n","    'The teacher rocks like a good rock & roll',\n","    'the rock is the best actor in the world',\n","    'New York is a beautiful city'\n","    ]\n","\n","# Obtenemos el token del primer documento\n","[tokenizador(doc) for doc in docs]"]},{"cell_type":"code","execution_count":10,"metadata":{"cell_id":"3d0f1a2529964cedb72ccc62a8e818a5","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":13,"execution_start":1637346927213,"source_hash":"2503a9b4","tags":[]},"outputs":[{"data":{"text/plain":["[['The', 'teacher', 'rocks', 'like', 'a', 'good', 'rock', '&', 'roll'],\n"," ['the', 'rock', 'is', 'the', 'best', 'actor', 'in', 'the', 'world'],\n"," ['New', 'York', 'is', 'a', 'beautiful', 'city']]"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["# Comparación con el caso anterior\n","docs_tokenizados = [word_tokenize(doc) for doc in docs]\n","docs_tokenizados"]},{"attachments":{},"cell_type":"markdown","metadata":{"cell_id":"937e18f6c6a747f7893b43a25d6aa65c","deepnote_cell_height":110.78125,"deepnote_cell_type":"markdown","tags":[]},"source":["#### Al Estilo Scikit\n","\n","Scikit implementa `bag of words` a través de la clase `CountVectorizer()` la cual contiene muchas opciones para mejorar la tokenización."]},{"cell_type":"code","execution_count":11,"metadata":{"cell_id":"c898d0dca5bd47cd80f4a8566cf5cc13","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":152,"execution_start":1637346927803,"source_hash":"2bc7124d","tags":[]},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>&amp;</th>\n","      <th>actor</th>\n","      <th>beauti</th>\n","      <th>best</th>\n","      <th>citi</th>\n","      <th>good</th>\n","      <th>like</th>\n","      <th>new</th>\n","      <th>rock</th>\n","      <th>roll</th>\n","      <th>teacher</th>\n","      <th>world</th>\n","      <th>york</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   &  actor  beauti  best  citi  good  like  new  rock  roll  teacher  world   \n","0  1      0       0     0     0     1     1    0     2     1        1      0  \\\n","1  0      1       0     1     0     0     0    0     1     0        0      1   \n","2  0      0       1     0     1     0     0    1     0     0        0      0   \n","\n","   york  \n","0     0  \n","1     0  \n","2     1  "]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["bow = CountVectorizer(tokenizer = StemmerTokenizer(), token_pattern=None)\n","df = bow.fit_transform(docs)\n","\n","pd.DataFrame(df.toarray(), columns=bow.get_feature_names_out())"]},{"attachments":{},"cell_type":"markdown","metadata":{"cell_id":"d9184cbee66a498bbe0050076342f306","deepnote_cell_height":155.953125,"deepnote_cell_type":"markdown","tags":[]},"source":["Una de las cosas más interesantes que provee son el use de n-gramas, los cuales, en palabras simples, son conjuntos de n-palabras que se concatenan entre si y que se consideran como tokens separados. \n","\n","Pensemos en `Nueva York`. Cuando se tokeniza Nueva York, se generan dos tokens independientes que a simple vista no tienen relación: `Nueva` `York`.\n","Al usar n-gramas (en un rango min=1,max=2) , generamos tanto `Nueva` y `York` como también `Nueva York` como un token independiente."]},{"cell_type":"code","execution_count":12,"metadata":{"cell_id":"8aa91d98ce4d4fd1b336e730702a9832","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":241,"execution_start":1637346930092,"source_hash":"6af25c7e","tags":[]},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>&amp;</th>\n","      <th>&amp; roll</th>\n","      <th>actor</th>\n","      <th>actor world</th>\n","      <th>beauti</th>\n","      <th>beauti citi</th>\n","      <th>best</th>\n","      <th>best actor</th>\n","      <th>citi</th>\n","      <th>good</th>\n","      <th>good rock</th>\n","      <th>like</th>\n","      <th>like good</th>\n","      <th>new</th>\n","      <th>new york</th>\n","      <th>rock</th>\n","      <th>rock &amp;</th>\n","      <th>rock best</th>\n","      <th>rock like</th>\n","      <th>roll</th>\n","      <th>teacher</th>\n","      <th>teacher rock</th>\n","      <th>world</th>\n","      <th>york</th>\n","      <th>york beauti</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   &  & roll  actor  actor world  beauti  beauti citi  best  best actor  citi   \n","0  1       1      0            0       0            0     0           0     0  \\\n","1  0       0      1            1       0            0     1           1     0   \n","2  0       0      0            0       1            1     0           0     1   \n","\n","   good  good rock  like  like good  new  new york  rock  rock &  rock best   \n","0     1          1     1          1    0         0     2       1          0  \\\n","1     0          0     0          0    0         0     1       0          1   \n","2     0          0     0          0    1         1     0       0          0   \n","\n","   rock like  roll  teacher  teacher rock  world  york  york beauti  \n","0          1     1        1             1      0     0            0  \n","1          0     0        0             0      1     0            0  \n","2          0     0        0             0      0     1            1  "]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["bow = CountVectorizer(tokenizer= StemmerTokenizer(), ngram_range=(1,2), token_pattern=None)\n","df = bow.fit_transform(docs)\n","\n","pd.DataFrame(df.toarray(), columns=bow.get_feature_names_out())"]},{"attachments":{},"cell_type":"markdown","metadata":{"cell_id":"81f6a40097954939a7854adbbe28fdc6","deepnote_cell_height":97.171875,"deepnote_cell_type":"markdown","tags":[]},"source":["De los resultados, podemos ver que generamos vectores de conteo para cada una de las palabras que conforman el corpus.  Un punto extra que se agrega en esta obtención de frecuencias son los bigramas, que básicamente son el conjunto de palabras de tamaño de aparecen juntas en el texto."]},{"attachments":{},"cell_type":"markdown","metadata":{"cell_id":"07780e17fbf349afaba37a0aef11e2f1","deepnote_cell_height":547,"deepnote_cell_type":"markdown","tags":[]},"source":["## Codificando los Super{heroes, villanos}  [0.5 Puntos]\n","\n","<p align=\"center\">\n","  <img src=\"https://c.tenor.com/LkQzw7k5DV4AAAAd/anime-hacking.gif\" width=\"300\">\n","</p>\n","\n","Conociendo ahora que es el proceso de `bag of words`, aplique este modelo de obtención de caracteristicas de la siguiente forma en un pipeline:\n","\n","- Utilice el tokenizador entregado.\n","- Obtenga caracteristicas de los unigramas y bigramas del texto (tal como el ejemplo).\n","\n","```python\n","bog = CountVectorizer(tokenizer= StemmerTokenizer(),`\n","                      ngram_range=(1,2) # Este punto es opcional y es para generar bigramas\n","                      )\n","```"]},{"attachments":{},"cell_type":"markdown","metadata":{"cell_id":"58abb21ee53c424a96ca09d3c3f91d51","deepnote_cell_height":332.90625,"deepnote_cell_type":"markdown","tags":[]},"source":["Finalmente, aplique `MinMaxScaler()` sobre `atributos_de_interes` y concatene el valor obtenido con el matriz de caracteristicas obtenidas con bag of words.\n","\n","```python\n","atributos_de_interes = ['intelligence_score', 'strength_score', 'speed_score', 'durability_score', 'power_score', 'combat_score']\n","```\n","\n","No es necesario que obtenga un dataframe en concreto con las características solicitadas. Se le recomienda generar un `ColumnTransformer()` para aplicar las transformaciones solicitadas en un pipeline.\n","\n","**To-Do:**\n","- [ ] Obtener a traves de Bag of Words (`CountVectorizer`) caracteristicas del resumen de historia de cada personaje.\n","- [ ] Aplicar `MinMaxScaler` sobre los atributos de interes."]},{"attachments":{},"cell_type":"markdown","metadata":{"cell_id":"a33d10178fa84f7f8834eeaddf78f4c4","deepnote_cell_height":52.390625,"deepnote_cell_type":"markdown","tags":[]},"source":["**Respuesta:**"]},{"cell_type":"code","execution_count":13,"metadata":{"cell_id":"20d7a7fe8e024e408b2016a1e4d6deef","deepnote_cell_height":66,"deepnote_cell_type":"code","id":"ay080DunHcOS"},"outputs":[],"source":["atributos_de_interes = ['intelligence_score', 'strength_score', 'speed_score', 'durability_score', 'power_score', 'combat_score']\n","\n","preprocessing = ColumnTransformer(\n","    transformers=[\n","        ('text', CountVectorizer(tokenizer= StemmerTokenizer(), ngram_range=(1,2), token_pattern=None), 'history_text'),\n","        ('numerical', MinMaxScaler(), atributos_de_interes)\n","    ])\n","\n","pipeline = Pipeline([\n","    (\"preprocessor\", preprocessing)\n","])"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"data":{"text/plain":["<1285x333926 sparse matrix of type '<class 'numpy.float64'>'\n","\twith 794030 stored elements in Compressed Sparse Row format>"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["transformed_data = pipeline.fit_transform(df_comics)\n","transformed_data"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text__!</th>\n","      <th>text__! !</th>\n","      <th>text__! ''</th>\n","      <th>text__! (</th>\n","      <th>text__! )</th>\n","      <th>text__! ,</th>\n","      <th>text__! --</th>\n","      <th>text__! .</th>\n","      <th>text__! ``</th>\n","      <th>text__! alison</th>\n","      <th>text__! almost</th>\n","      <th>text__! amazon</th>\n","      <th>text__! aquaman</th>\n","      <th>text__! begin</th>\n","      <th>text__! boil</th>\n","      <th>...</th>\n","      <th>text__�kick� driven</th>\n","      <th>text__�polic</th>\n","      <th>text__�polic man�</th>\n","      <th>text__�white</th>\n","      <th>text__�white room�</th>\n","      <th>text__�ǣmortal</th>\n","      <th>text__�ǣmortal instruments���</th>\n","      <th>text__��wors</th>\n","      <th>text__��wors ,</th>\n","      <th>numerical__intelligence_score</th>\n","      <th>numerical__strength_score</th>\n","      <th>numerical__speed_score</th>\n","      <th>numerical__durability_score</th>\n","      <th>numerical__power_score</th>\n","      <th>numerical__combat_score</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.85</td>\n","      <td>0.3</td>\n","      <td>0.60</td>\n","      <td>0.60</td>\n","      <td>0.40</td>\n","      <td>0.70</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.80</td>\n","      <td>1.0</td>\n","      <td>0.80</td>\n","      <td>1.00</td>\n","      <td>1.00</td>\n","      <td>0.80</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.80</td>\n","      <td>0.5</td>\n","      <td>0.55</td>\n","      <td>0.45</td>\n","      <td>1.00</td>\n","      <td>0.55</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.80</td>\n","      <td>0.1</td>\n","      <td>0.25</td>\n","      <td>0.40</td>\n","      <td>0.30</td>\n","      <td>0.50</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.90</td>\n","      <td>0.4</td>\n","      <td>0.45</td>\n","      <td>0.55</td>\n","      <td>0.55</td>\n","      <td>0.85</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>1280</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.90</td>\n","      <td>0.1</td>\n","      <td>0.25</td>\n","      <td>0.30</td>\n","      <td>1.00</td>\n","      <td>0.55</td>\n","    </tr>\n","    <tr>\n","      <th>1281</th>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.80</td>\n","      <td>1.0</td>\n","      <td>1.00</td>\n","      <td>1.00</td>\n","      <td>1.00</td>\n","      <td>0.80</td>\n","    </tr>\n","    <tr>\n","      <th>1282</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.95</td>\n","      <td>0.5</td>\n","      <td>1.00</td>\n","      <td>0.75</td>\n","      <td>1.00</td>\n","      <td>0.80</td>\n","    </tr>\n","    <tr>\n","      <th>1283</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.75</td>\n","      <td>0.1</td>\n","      <td>1.00</td>\n","      <td>0.30</td>\n","      <td>1.00</td>\n","      <td>0.30</td>\n","    </tr>\n","    <tr>\n","      <th>1284</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.45</td>\n","      <td>0.8</td>\n","      <td>0.75</td>\n","      <td>0.95</td>\n","      <td>0.80</td>\n","      <td>0.50</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1285 rows × 333926 columns</p>\n","</div>"],"text/plain":["      text__!  text__! !  text__! ''  text__! (  text__! )  text__! ,   \n","0         0.0        0.0         0.0        0.0        0.0        0.0  \\\n","1         0.0        0.0         0.0        0.0        0.0        0.0   \n","2         0.0        0.0         0.0        0.0        0.0        0.0   \n","3         0.0        0.0         0.0        0.0        0.0        0.0   \n","4         0.0        0.0         0.0        0.0        0.0        0.0   \n","...       ...        ...         ...        ...        ...        ...   \n","1280      0.0        0.0         0.0        0.0        0.0        0.0   \n","1281      1.0        0.0         1.0        0.0        0.0        0.0   \n","1282      0.0        0.0         0.0        0.0        0.0        0.0   \n","1283      0.0        0.0         0.0        0.0        0.0        0.0   \n","1284      0.0        0.0         0.0        0.0        0.0        0.0   \n","\n","      text__! --  text__! .  text__! ``  text__! alison  text__! almost   \n","0            0.0        0.0         0.0             0.0             0.0  \\\n","1            0.0        0.0         0.0             0.0             0.0   \n","2            0.0        0.0         0.0             0.0             0.0   \n","3            0.0        0.0         0.0             0.0             0.0   \n","4            0.0        0.0         0.0             0.0             0.0   \n","...          ...        ...         ...             ...             ...   \n","1280         0.0        0.0         0.0             0.0             0.0   \n","1281         0.0        0.0         0.0             0.0             0.0   \n","1282         0.0        0.0         0.0             0.0             0.0   \n","1283         0.0        0.0         0.0             0.0             0.0   \n","1284         0.0        0.0         0.0             0.0             0.0   \n","\n","      text__! amazon  text__! aquaman  text__! begin  text__! boil  ...   \n","0                0.0              0.0            0.0           0.0  ...  \\\n","1                0.0              0.0            0.0           0.0  ...   \n","2                0.0              0.0            0.0           0.0  ...   \n","3                0.0              0.0            0.0           0.0  ...   \n","4                0.0              0.0            0.0           0.0  ...   \n","...              ...              ...            ...           ...  ...   \n","1280             0.0              0.0            0.0           0.0  ...   \n","1281             0.0              0.0            0.0           0.0  ...   \n","1282             0.0              0.0            0.0           0.0  ...   \n","1283             0.0              0.0            0.0           0.0  ...   \n","1284             0.0              0.0            0.0           0.0  ...   \n","\n","      text__�kick� driven  text__�polic  text__�polic man�  text__�white   \n","0                     0.0           0.0                0.0           0.0  \\\n","1                     0.0           0.0                0.0           0.0   \n","2                     0.0           0.0                0.0           0.0   \n","3                     0.0           0.0                0.0           0.0   \n","4                     0.0           0.0                0.0           0.0   \n","...                   ...           ...                ...           ...   \n","1280                  0.0           0.0                0.0           0.0   \n","1281                  0.0           0.0                0.0           0.0   \n","1282                  0.0           0.0                0.0           0.0   \n","1283                  0.0           0.0                0.0           0.0   \n","1284                  0.0           0.0                0.0           0.0   \n","\n","      text__�white room�  text__�ǣmortal  text__�ǣmortal instruments���   \n","0                    0.0             0.0                            0.0  \\\n","1                    0.0             0.0                            0.0   \n","2                    0.0             0.0                            0.0   \n","3                    0.0             0.0                            0.0   \n","4                    0.0             0.0                            0.0   \n","...                  ...             ...                            ...   \n","1280                 0.0             0.0                            0.0   \n","1281                 0.0             0.0                            0.0   \n","1282                 0.0             0.0                            0.0   \n","1283                 0.0             0.0                            0.0   \n","1284                 0.0             0.0                            0.0   \n","\n","      text__��wors  text__��wors ,  numerical__intelligence_score   \n","0              0.0             0.0                           0.85  \\\n","1              0.0             0.0                           0.80   \n","2              0.0             0.0                           0.80   \n","3              0.0             0.0                           0.80   \n","4              0.0             0.0                           0.90   \n","...            ...             ...                            ...   \n","1280           0.0             0.0                           0.90   \n","1281           0.0             0.0                           0.80   \n","1282           0.0             0.0                           0.95   \n","1283           0.0             0.0                           0.75   \n","1284           0.0             0.0                           0.45   \n","\n","      numerical__strength_score  numerical__speed_score   \n","0                           0.3                    0.60  \\\n","1                           1.0                    0.80   \n","2                           0.5                    0.55   \n","3                           0.1                    0.25   \n","4                           0.4                    0.45   \n","...                         ...                     ...   \n","1280                        0.1                    0.25   \n","1281                        1.0                    1.00   \n","1282                        0.5                    1.00   \n","1283                        0.1                    1.00   \n","1284                        0.8                    0.75   \n","\n","      numerical__durability_score  numerical__power_score   \n","0                            0.60                    0.40  \\\n","1                            1.00                    1.00   \n","2                            0.45                    1.00   \n","3                            0.40                    0.30   \n","4                            0.55                    0.55   \n","...                           ...                     ...   \n","1280                         0.30                    1.00   \n","1281                         1.00                    1.00   \n","1282                         0.75                    1.00   \n","1283                         0.30                    1.00   \n","1284                         0.95                    0.80   \n","\n","      numerical__combat_score  \n","0                        0.70  \n","1                        0.80  \n","2                        0.55  \n","3                        0.50  \n","4                        0.85  \n","...                       ...  \n","1280                     0.55  \n","1281                     0.80  \n","1282                     0.80  \n","1283                     0.30  \n","1284                     0.50  \n","\n","[1285 rows x 333926 columns]"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["pd.DataFrame(transformed_data.toarray(), columns=pipeline.get_feature_names_out())"]},{"attachments":{},"cell_type":"markdown","metadata":{"cell_id":"9df292283e4449b2a4b5d60dcf2987c0","deepnote_cell_height":317.5,"deepnote_cell_type":"markdown","id":"stHncQ-A-j4I","owner_user_id":"d50c3174-babb-4861-9c71-7e3af66458b8"},"source":["## 1.2 Diseño de Baseline y  Primer Entrenamiento  [1 Puntos]\n","\n","\n","<p align=\"center\">\n","  <img src=\"https://pa1.narvii.com/6374/9eaec1b7bf9157334151452a669516f9a78b954c_hq.gif\" width=\"300\">\n","</p>\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"cell_id":"0de6d1a9fc4d400f972e7d0511ce2cf3","deepnote_cell_height":455.859375,"deepnote_cell_type":"markdown","id":"NeMiptpQ_EWb"},"source":["\n","Genere un Pipeline con las caracteristicas solicitadas en la sección 1.1, un selector de mejores features `SelectPercentile` con métrica `f_classif` y percentile=90 y un clasificador `MultinomialNB()` por defecto.\n","\n","Luego, separe el conjunto de datos en un conjunto de entrenamiento y prueba, donde las etiquetas estará dado por el atributo `alignment`. \n","\n","Entrene el modelo y reporte el desempeño con un `classification_report`. ¿Nos recomendaría predecir la alineación de BatCow con este clasificador?.\n","\n","Finalmente, compare el modelo entrenado con un modelo Dummy estratificado y responda: ¿El clasificador entrenado es mejor que el dummy que entrega respuestas al azar?\n","\n","**To-do:**\n","- [ ] Realizar un pipeline con las caracteristicas solicitadas en 1.1, ejecutar holdout y aplicar un clasificador `MultinomialNB()`.\n","- [ ] Entrenar el pipeline, calcular el `classification_report` asociado y comentar los resultados.\n","- [ ] Entrenar un `DummyClassifier` con estrategia `statified`, calcular el `classification_report` asociado y comentar que implican los scores obtenidos en comparación con los resultados del baseline."]},{"attachments":{},"cell_type":"markdown","metadata":{"cell_id":"81b793138ec14f3d92713dab4e6bebb9","deepnote_cell_height":52.390625,"deepnote_cell_type":"markdown","tags":[]},"source":["**Respuesta:**"]},{"cell_type":"code","execution_count":14,"metadata":{"cell_id":"e68a1a925b9d429d93f7b3e888eb9c06","deepnote_cell_height":66,"deepnote_cell_type":"code","id":"_hHpPDooPafy"},"outputs":[],"source":["pipeline_villain = Pipeline([\n","    (\"preprocessor\", preprocessing),\n","    (\"feature_selection\", SelectPercentile(score_func=f_classif, percentile=90)),\n","    ('clf', MultinomialNB())\n","])"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Classification Report:\n","              precision    recall  f1-score   support\n","\n","         Bad       0.73      0.13      0.22        85\n","        Good       0.63      0.99      0.77       153\n","     Neutral       1.00      0.05      0.10        19\n","\n","    accuracy                           0.63       257\n","   macro avg       0.79      0.39      0.36       257\n","weighted avg       0.69      0.63      0.54       257\n","\n"]}],"source":["X_train, X_test, y_train, y_test = train_test_split(df_comics.drop(columns = \"alignment\"), \n","                                                    df_comics[\"alignment\"], \n","                                                    train_size=0.8, \n","                                                    test_size=0.2, \n","                                                    random_state=8)\n","\n","# Entrenar el modelo\n","pipeline_villain.fit(X_train, y_train)\n","\n","# Predecir etiquetas para el conjunto de prueba\n","y_pred = pipeline_villain.predict(X_test)\n","\n","# Calcular el classification_report\n","report = classification_report(y_test, y_pred)\n","print(\"Classification Report:\")\n","print(report)"]},{"attachments":{},"cell_type":"markdown","metadata":{"cell_id":"f69a4b33bd9442fabbc34bcaf2c87581","deepnote_cell_height":70.796875,"deepnote_cell_type":"markdown","tags":[]},"source":["```\n","En términos generales, el algoritmo no logra un buen desempeño en la predicción y se equivoca bastante en la clase Bad y Neutral donde tiene un recall de 0.13 y 0.05 respectivamente, lo que isgnifica que le cuesta identificar esas clases cuando realmente lo son.\n","```"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Dummy Classification Report:\n","              precision    recall  f1-score   support\n","\n","         Bad       0.32      0.31      0.31        85\n","        Good       0.58      0.55      0.56       153\n","     Neutral       0.07      0.11      0.08        19\n","\n","    accuracy                           0.44       257\n","   macro avg       0.32      0.32      0.32       257\n","weighted avg       0.45      0.44      0.44       257\n","\n"]}],"source":["from sklearn.dummy import DummyClassifier\n","\n","# Comparar con un DummyClassifier estratificado\n","dummy = DummyClassifier(strategy='stratified', random_state=1)\n","dummy.fit(X_train, y_train)\n","y_dummy_pred = dummy.predict(X_test)\n","\n","dummy_report = classification_report(y_test, y_dummy_pred)\n","print(\"Dummy Classification Report:\")\n","print(dummy_report)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["```\n","Pese a no tener excelentes resultados con el modelo anterior, el pipeline sí es capaz de generar resultados que significan un mejor desempeño que el que tiene el modelo Dummy, lo cual es positivo pues DummyClassifier clasifica al azar las entradas.\n","```"]},{"attachments":{},"cell_type":"markdown","metadata":{"cell_id":"efd50fb630984a12a0a56ced0c73e088","deepnote_cell_height":400,"deepnote_cell_type":"markdown","id":"pfm7I2B7_rfB"},"source":["## 1.3 Busqueda del Mejor Modelo con Grid Search [4 Puntos]\n","\n","<p align=\"center\">\n","  <img src=\"https://media1.tenor.com/images/70fdfeea52a8e2e4505498c230a0d2f9/tenor.gif?itemid=5134219\" width=\"250\">\n","</p>"]},{"attachments":{},"cell_type":"markdown","metadata":{"cell_id":"69063d71deb042109162f3cb4199b231","deepnote_cell_height":859.5,"deepnote_cell_type":"markdown","id":"14siiavzK67p"},"source":["No conformes con el rendimiento obtenido en la sección 1.2, el cuerpo docente les pide que realicen un **`HalvingGridSearchCV`** con diferentes parámetros para mejorar el rendimiento de la clasificación. Para esto, se le solicita que defina:\n","\n","- Tres clasificadores distintos en donde varie sus parámetros. Considere usar modelos clásicos como también los basados en ensamblaje.\n","- Modificar `n-gram` range del `CountVectorizer` probando `(1,1), (1,2) y (1,3)`. Examinar también los otros parámetros de CountVectorizer como por ejemplo `max_df`, `min_df`, etc... ([Documentación aquí](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html))\n","- Seleccionar las columnas que contribuyen con la mayor información para la clasificación con `SelectPercentile` en los percentiles `[20, 40, 60, 80]` (puede usar la métrica que usted quiera).\n","- Reporte la mejor combinación encontrada y justifique por qué cree que es la mejor según el clasificador usado, la cantidad de columnas seleccionadas y los parámetros de CountVectorizer seleccionados por GridSearch.\n","\n","A continuación, un ejemplo de parametros para GridSearch para una búsqueda de 3 clasificadores distintos:\n","\n","```python\n","params = [\n","       # clasificador 1 + hiperparámetros\n","       {'clf': classificator1(),\n","        'clf__penalty': ['ovr'],\n","       # clasificador 1 + hiperparámetros    \n","       {'clf': classificator2(),\n","        'clf__n_estimators': [200]},\n","       # clasificador 1 + hiperparámetros\n","       {'clf': classificator3(),\n","        ...\n","       }\n","       ]\n","```\n","\n","**Nota 1**: Puede ver los parámetros modificables aplicando el método get_params() sobre su pipeline. Ver la clase de GridSearch para mayor información sobre la sintáxis de las grillas.\n","\n","**Nota 2**: Recuerde inicializar los clasificadores con un random state definido.\n","\n","**Nota 3**: Puede usar en `HalvingGridSearchCV` el parámetro `verbose=10` para ver que GridSearch le indique el estado de su ejecución.\n","\n","**Nota 3:** El GridSearch puede tomar tiempos de búsqueda exorbitantes, por lo que se le recomienda no agrandar mucho el espacio de búsqueda, dejar corriendo el código y tomarse un tecito."]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"data":{"text/plain":["{'memory': None,\n"," 'steps': [('preprocessor',\n","   ColumnTransformer(transformers=[('text',\n","                                    CountVectorizer(ngram_range=(1, 2),\n","                                                    token_pattern=None,\n","                                                    tokenizer=<__main__.StemmerTokenizer object at 0x000001B89C91C6D0>),\n","                                    'history_text'),\n","                                   ('numerical', MinMaxScaler(),\n","                                    ['intelligence_score', 'strength_score',\n","                                     'speed_score', 'durability_score',\n","                                     'power_score', 'combat_score'])])),\n","  ('feature_selection', SelectPercentile(percentile=90)),\n","  ('clf', MultinomialNB())],\n"," 'verbose': False,\n"," 'preprocessor': ColumnTransformer(transformers=[('text',\n","                                  CountVectorizer(ngram_range=(1, 2),\n","                                                  token_pattern=None,\n","                                                  tokenizer=<__main__.StemmerTokenizer object at 0x000001B89C91C6D0>),\n","                                  'history_text'),\n","                                 ('numerical', MinMaxScaler(),\n","                                  ['intelligence_score', 'strength_score',\n","                                   'speed_score', 'durability_score',\n","                                   'power_score', 'combat_score'])]),\n"," 'feature_selection': SelectPercentile(percentile=90),\n"," 'clf': MultinomialNB(),\n"," 'preprocessor__n_jobs': None,\n"," 'preprocessor__remainder': 'drop',\n"," 'preprocessor__sparse_threshold': 0.3,\n"," 'preprocessor__transformer_weights': None,\n"," 'preprocessor__transformers': [('text',\n","   CountVectorizer(ngram_range=(1, 2), token_pattern=None,\n","                   tokenizer=<__main__.StemmerTokenizer object at 0x000001B89C91C6D0>),\n","   'history_text'),\n","  ('numerical',\n","   MinMaxScaler(),\n","   ['intelligence_score',\n","    'strength_score',\n","    'speed_score',\n","    'durability_score',\n","    'power_score',\n","    'combat_score'])],\n"," 'preprocessor__verbose': False,\n"," 'preprocessor__verbose_feature_names_out': True,\n"," 'preprocessor__text': CountVectorizer(ngram_range=(1, 2), token_pattern=None,\n","                 tokenizer=<__main__.StemmerTokenizer object at 0x000001B89C91C6D0>),\n"," 'preprocessor__numerical': MinMaxScaler(),\n"," 'preprocessor__text__analyzer': 'word',\n"," 'preprocessor__text__binary': False,\n"," 'preprocessor__text__decode_error': 'strict',\n"," 'preprocessor__text__dtype': numpy.int64,\n"," 'preprocessor__text__encoding': 'utf-8',\n"," 'preprocessor__text__input': 'content',\n"," 'preprocessor__text__lowercase': True,\n"," 'preprocessor__text__max_df': 1.0,\n"," 'preprocessor__text__max_features': None,\n"," 'preprocessor__text__min_df': 1,\n"," 'preprocessor__text__ngram_range': (1, 2),\n"," 'preprocessor__text__preprocessor': None,\n"," 'preprocessor__text__stop_words': None,\n"," 'preprocessor__text__strip_accents': None,\n"," 'preprocessor__text__token_pattern': None,\n"," 'preprocessor__text__tokenizer': <__main__.StemmerTokenizer at 0x1b89c91c6d0>,\n"," 'preprocessor__text__vocabulary': None,\n"," 'preprocessor__numerical__clip': False,\n"," 'preprocessor__numerical__copy': True,\n"," 'preprocessor__numerical__feature_range': (0, 1),\n"," 'feature_selection__percentile': 90,\n"," 'feature_selection__score_func': <function sklearn.feature_selection._univariate_selection.f_classif(X, y)>,\n"," 'clf__alpha': 1.0,\n"," 'clf__class_prior': None,\n"," 'clf__fit_prior': True,\n"," 'clf__force_alpha': 'warn'}"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["pipeline_villain.get_params()"]},{"attachments":{},"cell_type":"markdown","metadata":{"cell_id":"7c9f3de702234ddca989bf2125fab779","deepnote_cell_height":52.390625,"deepnote_cell_type":"markdown","tags":[]},"source":["**Respuesta:**"]},{"cell_type":"code","execution_count":16,"metadata":{"cell_id":"4663cec8ef58413cb9cf36044d5c8da2","deepnote_cell_height":66,"deepnote_cell_type":"code","id":"oNvHOHELUoIv"},"outputs":[],"source":["# Definir los parámetros para GridSearch\n","params = [\n","    # Clasificador 1 + hiperparámetros\n","    {\n","        'clf': [SVC(random_state=42)],\n","        'clf__C': [0.1,1],\n","        'clf__kernel': ['linear','rbf'],\n","        'preprocessor__text__ngram_range': [(1, 1), (1, 2), (1, 3)],\n","        'preprocessor__text__max_df': [0.8, 1.0], # Ignorar palabras que aparecen en más del 80% o 100% de los documentos\n","        'preprocessor__text__min_df': [5], # Ignorar palabras que aparecen en menos de 5 documentos\n","        'feature_selection__percentile': [20, 40, 60, 80],\n","    },\n","    # Clasificador 2 + hiperparámetros\n","    {\n","        'clf': [RandomForestClassifier(random_state=42)],\n","        'clf__max_depth': [10,None],\n","        'clf__n_estimators': [50,100],\n","        'preprocessor__text__ngram_range': [(1, 1), (1, 2), (1, 3)],\n","        'preprocessor__text__max_df': [0.8, 1.0], # Ignorar palabras que aparecen en más del 80% o 100% de los documentos\n","        'preprocessor__text__min_df': [5], # Ignorar palabras que aparecen en menos de 5 documentos\n","        'feature_selection__percentile': [20, 40, 60, 80],\n","    },\n","    # Clasificador 3 + hiperparámetros\n","    {\n","        'clf': [LogisticRegression(random_state=42)],\n","        'clf__C': [0.1,1],\n","        'preprocessor__text__ngram_range': [(1, 1), (1, 2), (1, 3)],\n","        'preprocessor__text__max_df': [0.8, 1.0] ,# Ignorar palabras que aparecen en más del 80% o 100% de los documentos\n","        'preprocessor__text__min_df': [5], # Ignorar palabras que aparecen en menos de 5 documentos\n","        'feature_selection__percentile': [20, 40, 60, 80],\n","    }\n","]"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[],"source":["from sklearn.experimental import enable_halving_search_cv  # noqa\n","from sklearn.model_selection import HalvingGridSearchCV\n","\n","hgs = HalvingGridSearchCV(pipeline_villain, params, n_jobs=-1, scoring='f1_macro', verbose=10, cv=3)"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["n_iterations: 4\n","n_required_iterations: 5\n","n_possible_iterations: 4\n","min_resources_: 18\n","max_resources_: 1028\n","aggressive_elimination: False\n","factor: 3\n","----------\n","iter: 0\n","n_candidates: 240\n","n_resources: 18\n","Fitting 3 folds for each of 240 candidates, totalling 720 fits\n","----------\n","iter: 1\n","n_candidates: 80\n","n_resources: 54\n","Fitting 3 folds for each of 80 candidates, totalling 240 fits\n","----------\n","iter: 2\n","n_candidates: 27\n","n_resources: 162\n","Fitting 3 folds for each of 27 candidates, totalling 81 fits\n","----------\n","iter: 3\n","n_candidates: 9\n","n_resources: 486\n","Fitting 3 folds for each of 9 candidates, totalling 27 fits\n"]},{"name":"stderr","output_type":"stream","text":["e:\\Sebas\\anaconda3\\envs\\nlp\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n"]},{"data":{"text/html":["<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>HalvingGridSearchCV(cv=3,\n","                    estimator=Pipeline(steps=[(&#x27;preprocessor&#x27;,\n","                                               ColumnTransformer(transformers=[(&#x27;text&#x27;,\n","                                                                                CountVectorizer(ngram_range=(1,\n","                                                                                                             2),\n","                                                                                                token_pattern=None,\n","                                                                                                tokenizer=&lt;__main__.StemmerTokenizer object at 0x000001B89C91C6D0&gt;),\n","                                                                                &#x27;history_text&#x27;),\n","                                                                               (&#x27;numerical&#x27;,\n","                                                                                MinMaxScaler(),\n","                                                                                [&#x27;intelligence_score&#x27;,\n","                                                                                 &#x27;strength_score&#x27;,\n","                                                                                 &#x27;speed_score&#x27;,\n","                                                                                 &#x27;durability_score&#x27;,\n","                                                                                 &#x27;power_sc...\n","                                 &#x27;preprocessor__text__min_df&#x27;: [5],\n","                                 &#x27;preprocessor__text__ngram_range&#x27;: [(1, 1),\n","                                                                     (1, 2),\n","                                                                     (1, 3)]},\n","                                {&#x27;clf&#x27;: [LogisticRegression(C=1,\n","                                                            random_state=42)],\n","                                 &#x27;clf__C&#x27;: [0.1, 1],\n","                                 &#x27;feature_selection__percentile&#x27;: [20, 40, 60,\n","                                                                   80],\n","                                 &#x27;preprocessor__text__max_df&#x27;: [0.8, 1.0],\n","                                 &#x27;preprocessor__text__min_df&#x27;: [5],\n","                                 &#x27;preprocessor__text__ngram_range&#x27;: [(1, 1),\n","                                                                     (1, 2),\n","                                                                     (1, 3)]}],\n","                    scoring=&#x27;f1_macro&#x27;, verbose=10)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">HalvingGridSearchCV</label><div class=\"sk-toggleable__content\"><pre>HalvingGridSearchCV(cv=3,\n","                    estimator=Pipeline(steps=[(&#x27;preprocessor&#x27;,\n","                                               ColumnTransformer(transformers=[(&#x27;text&#x27;,\n","                                                                                CountVectorizer(ngram_range=(1,\n","                                                                                                             2),\n","                                                                                                token_pattern=None,\n","                                                                                                tokenizer=&lt;__main__.StemmerTokenizer object at 0x000001B89C91C6D0&gt;),\n","                                                                                &#x27;history_text&#x27;),\n","                                                                               (&#x27;numerical&#x27;,\n","                                                                                MinMaxScaler(),\n","                                                                                [&#x27;intelligence_score&#x27;,\n","                                                                                 &#x27;strength_score&#x27;,\n","                                                                                 &#x27;speed_score&#x27;,\n","                                                                                 &#x27;durability_score&#x27;,\n","                                                                                 &#x27;power_sc...\n","                                 &#x27;preprocessor__text__min_df&#x27;: [5],\n","                                 &#x27;preprocessor__text__ngram_range&#x27;: [(1, 1),\n","                                                                     (1, 2),\n","                                                                     (1, 3)]},\n","                                {&#x27;clf&#x27;: [LogisticRegression(C=1,\n","                                                            random_state=42)],\n","                                 &#x27;clf__C&#x27;: [0.1, 1],\n","                                 &#x27;feature_selection__percentile&#x27;: [20, 40, 60,\n","                                                                   80],\n","                                 &#x27;preprocessor__text__max_df&#x27;: [0.8, 1.0],\n","                                 &#x27;preprocessor__text__min_df&#x27;: [5],\n","                                 &#x27;preprocessor__text__ngram_range&#x27;: [(1, 1),\n","                                                                     (1, 2),\n","                                                                     (1, 3)]}],\n","                    scoring=&#x27;f1_macro&#x27;, verbose=10)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n","                 ColumnTransformer(transformers=[(&#x27;text&#x27;,\n","                                                  CountVectorizer(ngram_range=(1,\n","                                                                               2),\n","                                                                  token_pattern=None,\n","                                                                  tokenizer=&lt;__main__.StemmerTokenizer object at 0x000001B89C91C6D0&gt;),\n","                                                  &#x27;history_text&#x27;),\n","                                                 (&#x27;numerical&#x27;, MinMaxScaler(),\n","                                                  [&#x27;intelligence_score&#x27;,\n","                                                   &#x27;strength_score&#x27;,\n","                                                   &#x27;speed_score&#x27;,\n","                                                   &#x27;durability_score&#x27;,\n","                                                   &#x27;power_score&#x27;,\n","                                                   &#x27;combat_score&#x27;])])),\n","                (&#x27;feature_selection&#x27;, SelectPercentile(percentile=90)),\n","                (&#x27;clf&#x27;, MultinomialNB())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">preprocessor: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[(&#x27;text&#x27;,\n","                                 CountVectorizer(ngram_range=(1, 2),\n","                                                 token_pattern=None,\n","                                                 tokenizer=&lt;__main__.StemmerTokenizer object at 0x000001B89C91C6D0&gt;),\n","                                 &#x27;history_text&#x27;),\n","                                (&#x27;numerical&#x27;, MinMaxScaler(),\n","                                 [&#x27;intelligence_score&#x27;, &#x27;strength_score&#x27;,\n","                                  &#x27;speed_score&#x27;, &#x27;durability_score&#x27;,\n","                                  &#x27;power_score&#x27;, &#x27;combat_score&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">text</label><div class=\"sk-toggleable__content\"><pre>history_text</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer(ngram_range=(1, 2), token_pattern=None,\n","                tokenizer=&lt;__main__.StemmerTokenizer object at 0x000001B89C91C6D0&gt;)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">numerical</label><div class=\"sk-toggleable__content\"><pre>[&#x27;intelligence_score&#x27;, &#x27;strength_score&#x27;, &#x27;speed_score&#x27;, &#x27;durability_score&#x27;, &#x27;power_score&#x27;, &#x27;combat_score&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MinMaxScaler</label><div class=\"sk-toggleable__content\"><pre>MinMaxScaler()</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SelectPercentile</label><div class=\"sk-toggleable__content\"><pre>SelectPercentile(percentile=90)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"],"text/plain":["HalvingGridSearchCV(cv=3,\n","                    estimator=Pipeline(steps=[('preprocessor',\n","                                               ColumnTransformer(transformers=[('text',\n","                                                                                CountVectorizer(ngram_range=(1,\n","                                                                                                             2),\n","                                                                                                token_pattern=None,\n","                                                                                                tokenizer=<__main__.StemmerTokenizer object at 0x000001B89C91C6D0>),\n","                                                                                'history_text'),\n","                                                                               ('numerical',\n","                                                                                MinMaxScaler(),\n","                                                                                ['intelligence_score',\n","                                                                                 'strength_score',\n","                                                                                 'speed_score',\n","                                                                                 'durability_score',\n","                                                                                 'power_sc...\n","                                 'preprocessor__text__min_df': [5],\n","                                 'preprocessor__text__ngram_range': [(1, 1),\n","                                                                     (1, 2),\n","                                                                     (1, 3)]},\n","                                {'clf': [LogisticRegression(C=1,\n","                                                            random_state=42)],\n","                                 'clf__C': [0.1, 1],\n","                                 'feature_selection__percentile': [20, 40, 60,\n","                                                                   80],\n","                                 'preprocessor__text__max_df': [0.8, 1.0],\n","                                 'preprocessor__text__min_df': [5],\n","                                 'preprocessor__text__ngram_range': [(1, 1),\n","                                                                     (1, 2),\n","                                                                     (1, 3)]}],\n","                    scoring='f1_macro', verbose=10)"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["hgs.fit(X_train, y_train)"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Best f1-macro: 0.4215892567750395\n","Best params: {'clf': LogisticRegression(C=1, random_state=42), 'clf__C': 1, 'feature_selection__percentile': 20, 'preprocessor__text__max_df': 1.0, 'preprocessor__text__min_df': 5, 'preprocessor__text__ngram_range': (1, 2)}\n"]}],"source":["print(f'Best f1-macro: {hgs.best_score_}')\n","print(f'Best params: {hgs.best_params_}')"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","         Bad       0.61      0.56      0.59        85\n","        Good       0.76      0.83      0.79       153\n","     Neutral       0.30      0.16      0.21        19\n","\n","    accuracy                           0.69       257\n","   macro avg       0.55      0.52      0.53       257\n","weighted avg       0.67      0.69      0.68       257\n","\n"]}],"source":["y_pred = hgs.predict(X_test) \n","print(classification_report(y_test, y_pred))"]},{"attachments":{},"cell_type":"markdown","metadata":{"cell_id":"807d969e26fc4b049be6482e527b12a4","deepnote_cell_height":70.796875,"deepnote_cell_type":"markdown","tags":[]},"source":["Se puede observar que los resultados son mejores al modelo testeado en la parte anterior de Multinomial Naive Bayes. Pasamos de un Accuracy de 0.63 a 0.69 y una mejora relevante en el recall de la clase Bad(0.12 a 0.56) y en Neutral(0.05 a 0.16). Asimismo, los mejores resultados dan con los siguientes parámetros:\n","\n","```python\n","{\n","    'clf': LogisticRegression(C=1, random_state=42), \n","    'clf__C': 1, \n","    'feature_selection__percentile': 20, \n","    'preprocessor__text__max_df': 1.0,\n","    'preprocessor__text__min_df': 5, \n","    'preprocessor__text__ngram_range': (1, 2)\n","}\n","```\n","\n","De los modelos testeados, la regresión logística resulta ser el mejor de los modelos probados. De los parámetros obtenidos, es interesante notar el de ``feature_selection__percentile``, el cual arroja mejores resultados seleccionado el 20% de las features que poseen más importancia en función del criterio de ``f_classif`` el cual computa el test estadístico de ANOVA. En otras palabras, la selección de caracteríscas resulta arrojar los mejores resultados. Asimismo, se obtiene que usando Bigramas aporta enormemente a los resultados. Y por otro lado, ``max_df`` 1.0 nos indica que se ignoran aquellas palabras que aparecen en todos los documentos, las cuales podrían ser de manera indirecta stopwords y no estar filtradas previamente en el tokenizador que creamos. Y el parámetro de regularización ``C=1`` desempeñó mejor que 0.1."]},{"attachments":{},"cell_type":"markdown","metadata":{"cell_id":"e4fd03fac45b4d288f6c67f8bbbf8c18","deepnote_cell_height":600.15625,"deepnote_cell_type":"markdown","id":"OmQUw2aZ_6z2"},"source":["## 1.4 Predicción del datos sin etiquetado  [0.5 puntos]\n","\n","<p align=\"center\">\n","  <img src=\"https://pbs.twimg.com/media/DolotxUUYAAbg7f.jpg\" width=\"350\">\n","</p>\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"cell_id":"7f4aa54f58fd436f99c206aab5be6850","deepnote_cell_height":111.171875,"deepnote_cell_type":"markdown","id":"Cj0ERBgTBFWN"},"source":["LLego el momento de predecir \n","`Vergil`, `Gorilla Girl` y `Batcow`\n","\n","\n","**Nota:** Recuerde que pueden existir campos vacios en `history_text`, por lo que se les recomienda borrar los nan."]},{"attachments":{},"cell_type":"markdown","metadata":{"cell_id":"6c3937a8832f4c48bbad30dc1b27d42d","deepnote_cell_height":52.390625,"deepnote_cell_type":"markdown","tags":[]},"source":["**Respuesta:**"]},{"cell_type":"code","execution_count":53,"metadata":{},"outputs":[],"source":["df_comics_no_label = df_comics_no_label.dropna(subset=['history_text']).drop_duplicates() # eliminar ejemplos sin historia y duplicados"]},{"cell_type":"code","execution_count":54,"metadata":{},"outputs":[],"source":["df_comics_no_label['alignment'] = hgs.predict(df_comics_no_label)"]},{"cell_type":"code","execution_count":55,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>name</th>\n","      <th>alignment</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>16</th>\n","      <td>Batcow</td>\n","      <td>Good</td>\n","    </tr>\n","    <tr>\n","      <th>40</th>\n","      <td>Gorilla Girl</td>\n","      <td>Good</td>\n","    </tr>\n","    <tr>\n","      <th>78</th>\n","      <td>Vergil</td>\n","      <td>Good</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["            name alignment\n","16        Batcow      Good\n","40  Gorilla Girl      Good\n","78        Vergil      Good"]},"execution_count":55,"metadata":{},"output_type":"execute_result"}],"source":["df_comics_no_label.loc[df_comics_no_label.name.isin(['Vergil', 'Gorilla Girl','Batcow']), ['name', 'alignment']]"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["```\n","Finalmente podemos observar que el modelo arroja que la alineación de estos personajes es buena 😁\n","```"]},{"attachments":{},"cell_type":"markdown","metadata":{"cell_id":"0ee55c847633405fb2e7cfaade1fc799","deepnote_cell_height":269,"deepnote_cell_type":"markdown","id":"Rg4ZMq8ezAH6"},"source":["<p align=\"center\">\n","  <img src=\"https://media1.tenor.com/images/fb5bf7cc5a4acb91b4177672886a88ba/tenor.gif?itemid=5591338\">\n","</p>"]},{"attachments":{},"cell_type":"markdown","metadata":{"created_in_deepnote_cell":true,"deepnote_cell_type":"markdown"},"source":["<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=87110296-876e-426f-b91d-aaf681223468' target=\"_blank\">\n","<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\n","Created in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>"]}],"metadata":{"colab":{"collapsed_sections":["LCOUC4jss148","GtG74Cphq56p"],"name":"Laboratorio4.ipynb","provenance":[],"toc_visible":true},"deepnote":{},"deepnote_execution_queue":[],"deepnote_notebook_id":"b7ffc7ddb4f14fcd976082c27e48a913","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.2"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":true,"title_cell":"Tabla de Contenidos","title_sidebar":"Contenidos","toc_cell":false,"toc_position":{"height":"calc(100% - 180px)","left":"10px","top":"150px","width":"241.867px"},"toc_section_display":true,"toc_window_display":true},"varInspector":{"cols":{"lenName":16,"lenType":16,"lenVar":40},"kernels_config":{"python":{"delete_cmd_postfix":"","delete_cmd_prefix":"del ","library":"var_list.py","varRefreshCmd":"print(var_dic_list())"},"r":{"delete_cmd_postfix":") ","delete_cmd_prefix":"rm(","library":"var_list.r","varRefreshCmd":"cat(var_dic_list()) "}},"types_to_exclude":["module","function","builtin_function_or_method","instance","_Feature"],"window_display":false}},"nbformat":4,"nbformat_minor":0}
